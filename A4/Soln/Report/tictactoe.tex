%------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{subcaption}
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
% Optional Packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}


% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{\hmwkAuthorName} % Top left header
\chead{\hmwkClass\ : \hmwkTitle} % Top center head
%\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs


%------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
	%\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
	%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
	%\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
	%\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems
\setcounter{homeworkProblemCounter}{0}

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
	\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
	\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
	\section{\homeworkProblemName} % Make a section in the document with the custom problem count
	\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
	\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
	\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
	\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
	\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
	\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
	\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}


%=================================================================

%------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Assignment\ \#4} % Assignment title
\newcommand{\hmwkClass}{CSC 411} % Course/class
\newcommand{\hmwkAuthorName}{Xiangyu Kong \hspace{3em} Yun Lu} % Your name
\newcommand{\hmwkUTorId}{kongxi16 \hspace{5em} luyun5} % UTorID

%------------------------------------------------------------------------------------
%	TITLE PAGE
%------------------------------------------------------------------------------------

\title{
	\vspace{2in}
	\textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
	%	\normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
	\vspace{0.1in}
	\vspace{3in}
}

\author{\textbf{\hmwkAuthorName} \\ \textbf{\hmwkUTorId}}

% Insert date here if you want it to appear below your name
\date{\today}

%------------------------------------------------------------------------------------

\begin{document}
	
	\maketitle
	\clearpage
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 1
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		In class ``Environment", the ``grid" is represented by an 1-D array of 9 elements. Attribute ``turn" represents whose turn it is. The valid values for ``turn" is either 1 (x) or 2 (o). Attribute ``done" represents whether the game is done.
		
		The code and output of a game is shown in the listing below.
		
		\begin{lstlisting}[caption = Code and Output of a game]
		for i in range(9):
			env.step(i)
			env.render()
		return
		x..
		...
		...
		====
		xo.
		...
		...
		====
		xox
		...
		...
		====
		xox
		o..
		...
		====
		xox
		ox.
		...
		====
		xox
		oxo
		...
		====
		xox
		oxo
		x..
		====
		xox
		oxo
		x..
		====
		xox
		oxo
		x..
		====
		\end{lstlisting}
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 2
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}

		\begin{enumerate}
			\item 
			The Policy class is implemented in the listing below. The network consist of one hidden layer and the activations used are ReLU activation.
			\begin{lstlisting}[language = python, caption = policy]
class Policy(nn.Module):
	def __init__(self, input_size=27, hidden_size=64, output_size=9):
		super(Policy, self).__init__()
		self.network = nn.Sequential(
			nn.Linear(input_size, hidden_size),
			nn.ReLU(),
			nn.Linear(hidden_size, output_size),
			nn.ReLU())
	def forward(self, x):
		return self.network(x)
			\end{lstlisting}
			
			\item 
			The 27-dimensional vector should be viewed as a $3 \times 9$ matrices with each column as a one-hot vector. The column number represents the position on the grid (1st column represent Environment.grid[0]), and the vector itself represents the state of the current position. The state correspond to the map in Environment.render() (\{0: '.', 1: 'x', 2: 'o'\}).
			
			\item 
			The 9 values Policy returns are the probabilities that it chooses the corresponding next move (e.g. the first element represents the probability that the next move is chosen to be placed at the first element in Environment.grid).
			
			The select\_action samples the action according to the probabilities (stochastic) instead of choosing the maximum probability (deterministic). Then the policy is stochastic.
			
		\end{enumerate}
		
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 3
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		\begin{enumerate}
			\item 
			the implementation for compute\_returns is shown in the listing below.
			\begin{lstlisting}[language = python, caption = compute return]
def compute_returns(rewards, gamma = 1.0):
	res = []
	for i in range(len(rewards)):
		curr_return = 0
		cur_rewards = rewards[i:]
		for j in range(len(cur_rewards)):
			curr_return += cur_rewards[j] * (gamma ** j)
		res.append(curr_return)
	return res
			\end{lstlisting}
			
			\item 
			The backward pass cannot be computed during the episode because the reward is not fully recorded and thus computing the gradient may produce a biased return.
			
		\end{enumerate}
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 4
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		\begin{enumerate}
			\item 
			See tictactoe.py for implementations.
			
			\item 
			The rewards are shown in the listing below. The win and lose rewards are $+100$ and $-100$ respectively. The reward for valid move is 5 and for invalid move is $-50$. This is because we do not want the network to make invalid moves and do not want the network to be satisfied with just making valid moves. Finally, we reward tie as $-10$. This is because getting a tied result is just a little bit better than losing, but still not what we wanted, so we discourage the policy to get a tied score.
			
			\begin{lstlisting}[caption = Rewards]
	Environment.STATUS_VALID_MOVE: 5, 
	Environment.STATUS_INVALID_MOVE: -50,
	Environment.STATUS_WIN: 100,
	Environment.STATUS_TIE: -10,
	Environment.STATUS_LOSE: -100
			\end{lstlisting}
		\end{enumerate}
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 5
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		\begin{enumerate}
			\item 
			The training curve is shown in Fig.\ref{fig:5}. The hyperparameters are as follows: lr = 0.0005, gamma = 0.9, max\_iter = 50000. We set gamma to 0.9 to get a smoother and quicker result. We also set the learning rate to half to make sure the training does not get stuck. If the learning rate is too high, the weights will grow too fast and the policy will try to pick the same choice over and over again.
		
			\begin{figure}[!ht]
				\centering
				\includegraphics[width=.75\linewidth]{images/5/training_curve.png}
				\caption{Training Curve}
				\label{fig:5}
			\end{figure}
			
			\item 
			The hidden dimension was tested on values [32, 64, 128, 256]. Their results were calculated using function get\_policy\_result. The best-performing dimension was {256}. It has {946} wins out of 1000 round.
			
			
			\item 
			The policy starts to understand not to make invalid moves at around the {5000}th iteration.  To get this result, we let the policy play with random for 100 times at each log point and count the number of invalid move and total move and thus calculate the percentage of the invalid move the policy makes. After the {5000}th iteration, all iterations' invalid move rates are less than 3\%, so the policy understands not to make invalid moves.
			
			\item 
			By looking at the game plays, we can see that the policy is capable of understanding how to block the opponent from making a winning-move. While the policy is doing that, it also tries to place the crosses at a place that is advantageous.
			\begin{lstlisting}
	==================== Game 0 ====================
	..x
	...
	.o.
	====
	.ox
	...
	xo.
	====
	.ox
	.x.
	xo.
	====
	==================== Game 1 ====================
	o.x
	...
	...
	====
	o.x
	..o
	.x.
	====
	o.x
	o.o
	xx.
	====
	o.x
	oxo
	xx.
	====
	==================== Game 2 ====================
	...
	o..
	.x.
	====
	..x
	o.o
	.x.
	====
	.ox
	oxo
	.x.
	====
	.ox
	oxo
	xx.
	====
	==================== Game 3 ====================
	..x
	...
	o..
	====
	..x
	.x.
	o.o
	====
	..x
	xx.
	ooo
	====
	==================== Game 4 ====================
	..x
	..o
	...
	====
	..x
	.xo
	o..
	====
	..x
	.xo
	oox
	====
	x.x
	.xo
	oox
	====
			\end{lstlisting}
		\end{enumerate}
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 6
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		The performance for different stages are shown in Fig.\ref{fig:6}. From the graph we can clearly see that the winning rate increases from less than $60\%$ to around $80\%$ and the lose and tie rates gradually decrease. This is because we want the network to maximize reward and we only set the reward for winning to be positive, so the network learns to win more.
		\begin{figure}[!ht]
			\centering
			\includegraphics[width=.75\linewidth]{images/6/performance_curve.png}
			\caption{Performance over time}
			\label{fig:6}
		\end{figure}
		
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 7
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		The final first move distribution is [0.002, 0.0061, 0.0003, 0.0, 0.0, 0.9859, 0.0035, 0.002, 0.0002]. We can clearly see that the network understands that it should play the first move at slot 6 (grid[2, 3]).
		
		The distribution throughout the training process is shown in Fig.\ref{fig:7}. We can see that the policy struggled between position 6 and 8 a lot. Surprisingly, it did not try to focus on position 5, which most people would.
		
		\begin{figure*}[!ht]
			\centering
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_1.png}
				\caption{Distribution for position 1}
				\label{fig:7.1}
			\end{subfigure}
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_2.png}
				\caption{Distribution for position 2}
				\label{fig:7.2}
			\end{subfigure}
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_3.png}
				\caption{Distribution for position 3}
				\label{fig:7.3}
			\end{subfigure}
			
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_4.png}
				\caption{Distribution for position 4}
				\label{fig:7.4}
			\end{subfigure}
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_5.png}
				\caption{Distribution for position 5}
				\label{fig:7.5}
			\end{subfigure}
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_6.png}
				\caption{Distribution for position 6}
				\label{fig:7.6}
			\end{subfigure}
		
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_7.png}
				\caption{Distribution for position 7}
				\label{fig:7.7}
			\end{subfigure}
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_8.png}
				\caption{Distribution for position 8}
				\label{fig:7.8}
			\end{subfigure}
			\begin{subfigure}{.3\textwidth}
				\centering
				\includegraphics[width=\linewidth]{images/7/move_dist_9.png}
				\caption{Distribution for position 9}
				\label{fig:7.9}
			\end{subfigure}
			\caption{First move distributions}
			\label{fig:7}
		\end{figure*}
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	
	%---------------------------------------------------------------------------------
	%	PROBLEM 8
	%---------------------------------------------------------------------------------
	\begin{homeworkProblem}
		%		\noindent \textit{Question}
		One reason that the policy fails is that it does not focus on the upper or lower rows when the opponent is about to win on the. It usually just ignore those rows even if the opponent has already have 2 stones on it.
		
	\end{homeworkProblem}
	\clearpage
	
	%----------------------------------------------------------------------------------
	
	%---------------------------------------------------------------------------------
\end{document}